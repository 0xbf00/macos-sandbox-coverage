"""
Module to generalise matching results.

We perform two steps here:
1. Match concrete matching results with a generalised version of the app's sandboxing profile
2. Match the "generalised app matching results" with a single general sandboxing profile
"""
import json
import operator

from maap.misc.logger import create_logger

logger = create_logger('sbprofiles.generalise')


def create_matching(base_profile: list,
                    reduced_profile: list,
                    compare_func = operator.eq) -> dict:
    """Create a matching between two (slightly) different rulesets.

    Precondition: len(base_profile) >= len(reduced_profile)

    :param base_profile The unchanged base profile. Assumed to have at least as many rules as
                        the reduced profile
    :param reduced_profile The "reduced" profile, i.e. the normalised version. This reduced
                           profile commonly has exactly as many rules as the original profile.
                           However, in some cases it is possible that the reduced profile has
                           fewer rules, as application specific rules are generated by the Sandbox.
    :param compare_func The comparison function to use to compare two sandbox rules with one another.
    :returns dictionary mapping rule i of the base profile to rule j of the reduced profile, or -1
             if the mapping failed.
    """
    assert isinstance(base_profile, list)
    assert isinstance(reduced_profile, list)
    assert len(base_profile) >= len(reduced_profile)

    matched_indices = set()
    matches = {}

    for i, rule in enumerate(base_profile):
        # Base profile and reduced profile are related in the sense that the reduced
        # profile is based off of the same base profile. By studying the sandbox profile
        # generation algorithm, we can say that rule i will only ever match with
        # rule j in the reduced profile if j <= i, that is to say, the sandbox generates
        # never generates _more_ rules than for the concrete app and the order of the rules
        # is the same. We therefore stop iteration at index i, because otherwise we get
        # nonsensical matches where the application matches with an entirely unrelated
        # rule at the back of the ruleset.
        for j, other_rule in enumerate(reduced_profile[0:i+1]):
            # Make sure not to match a rule twice.
            if compare_func(rule, other_rule) and j not in matched_indices:
                matches[i] = j
                matched_indices.add(j)
                break
        else:
            matches[i] = -1

    return matches


def group_consecutives(vals, step=1):
    """Return list of consecutive lists of numbers from vals (number list)."""
    run = []
    result = [run]
    expect = None
    for v in vals:
        if (v == expect) or (expect is None):
            run.append(v)
        else:
            run = [v]
            result.append(run)
        expect = v + step
    return result


def display_matches(matches, normalised, general):
    matches = [matches[k] for k in sorted(matches.keys())]

    grouped_matches = group_consecutives(matches)
    overall_index = 0

    for group in grouped_matches:
        print("{} -> {}".format(range(overall_index, overall_index + len(group)), group))
        if group[0] != -1:
            print("{} -> {}".format(normalised[overall_index], general[group[0]]))
        overall_index += len(group)


def match_rules(original: dict, normalised: dict, general: dict):
    """
    Computes an aggregate matching relation, mapping rules from the application profile
    to the final generic profile.
    """
    # Compute first matching between app profile and generic version
    # Because the normalised sandbox profile uses generic placeholder values for
    # things such as paths, we only compare the action (allow | deny) and the
    # involved operations and ignore any filters
    comparator = lambda x, y: (x['action'] == y['action']) and (x['operations'] == y['operations'])
    first_matching = create_matching(original, normalised, comparator)

    # Compute matching between generic app profile and generic profile
    # Both the normalised and the general profile use the same placeholders for
    # things such as paths. As such, we compare the entire rule, including
    # filters and modifiers
    second_matching = create_matching(normalised, general)

    # return aggregate matching (a -> c) where (a -> b) and (b -> c)
    return {
        a: second_matching.get(b, -1) for a, b in first_matching.items()
    }


def generalise_results(state: dict) -> (bool, dict):
    """Process and transform collected matching results into a form that is usable for
    the generic profile we use for visualisation at the end."""
    matches = state['match_results']['original']
    original_profile = json.loads(state['sandbox_profiles']['original'])
    normalised_profile = state['sandbox_profiles']['normalised']
    general_profile = state['sandbox_profiles']['general']

    rule_mapping = match_rules(original_profile, normalised_profile, general_profile)

    # Applying the rule mapping to the matches to get general_matches
    general_matches = {
        match_idx: rule_mapping[rule_idx] if rule_idx not in ["inconsistent", "external"]
                                          else -1
            for match_idx, rule_idx in matches
    }

    state['match_results']['general'] = general_matches
    return True, state